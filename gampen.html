<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>GaMPEN | Galaxy Morphology Posterior Estimation Network</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="description" content="GaMPEN (Galaxy Morphology Posterior Estimation 
		Network) can accurately estimate posteriors for different galaxy morphological parameters." />
        <meta name="keywords" content="gampen, galaxy morphology posterior estimation network,
		galaxy morphology posterior, bayesian deep learning, astronomy bayesian deep learning,
		bayesian neural network, astronomy bayesian neural network" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>


		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-47Z4SFM7FZ"></script>
		<script>
 		 window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
  		gtag('js', new Date());

  		gtag('config', 'G-47Z4SFM7FZ');
		</script>
		
        <!-- ACTIVATING MATHJAX TO WRITE LATEX   -->	
		<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              processEscapes: true
            }
          });
       	</script>
       	<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
		
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Aritra | &#x0985;&#x09B0;&#x09BF;&#x09A4;&#x09CD;&#x09B0;&nbsp;</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="about_me.html">About Me</a></li>
							<li><a href="research.html">Research</a></li>
							<li><a href="teaching.html">Teaching &amp Mentoring</a></li>
							<li><a href="outreach.html">Outreach</a></li>
							<li><a href="advocacy.html">Advocacy</a></li>	
							<li><a href="cv.html">CV</a></li>			
						</ul>
						<ul class="icons">
							<li><a href="mailto:aritraghsh09@gmail.com" target="_blank" class="icon fa-envelope"><span class="label">Email</span></a></li>
							<li><a href="https://github.com/aritraghsh09" target="_blank"  class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="https://twitter.com/aritraghsh09" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.linkedin.com/in/aritra-ghosh-169ba582" target="_blank" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						</ul>
					</nav>


				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">

								<header class="major">
									<h1 style="text-transform: none;">GaMPEN</h1>

									<span class="image fit" style="max-width: 90%;
									display: block;
 									margin-left: auto;
  									margin-right: auto;">
									<img src="images/research/gampen_intro.png" alt="Schematic Diagram showing
									the basic inner working of GaMPEN. It takes an input image to first crop
									it and then estimate posterior distributions of different morphological 
									parameters"/></span>


									<h3>Galaxy Morphology Posterior Estimation Network</h3>
									<p>The first ML framework for automatic cropping &amp; estimating posteriors of different galaxy
										morphological parameters</p>

									<ul class="actions special wrap">
										<li><a href="https://arxiv.org/abs/2207.05107" class="button primary small" 
											target="_blank">ArXiv</i></a></li>
										<li><a href="https://doi.org/10.3847/1538-4357/ac7f9e" 
											class="button primary small" target="_blank">ApJ</a></li>
										<li><a href="https://github.com/aritraghsh09/GaMPEN" class="button primary small" target="_blank">Source Code</a></li> 
										<li><a href="https://gampen.readthedocs.io/" class="button primary small" target="_blank">Docs. & Tutorials</a></li>
										<li><a href="https://gampen.readthedocs.io/en/latest/Public_data.html" 
											class="button primary small" target="_blank">HSC Morph. Catalog</a></li>
									</ul>
							
								</header>

								<hr />

								<h3>What does GaMPEN do & Why was it needed?</h3>
								<p>
									Although Convolutional Neural Networks (CNNs) have used for galaxy morphology determination
									for quite some time now, a few challenges associated with the process has persisted. From the
									early attempts at using a CNN to classify galaxies morphologically to the largest ML-produced
									morphological catalogs currently available, <b><em>most CNNs have provided broad morphological
									classifications.</em></b> There has been very limited work on estimating morphological parameters
									using CNNs; and <em><b>there has been no work on estimating robust uncertainties of CNN determined
									morphological parameters. Even popular non-ML tools like Galfit severely underestimate uncertainties
									by values as high as $\sim75\%$</b></em>. Meanwhile, the computation of full Bayesian posteriors for
									different morphological parameters is crucial for drawing scientific inferences that account for 
									uncertainty and thus are indispensable in the derivation of robust scaling relations or tests of 
									theoretical models using morphology.</p>

								<p> One other challenge of using CNNs in astronomy, is the necessity ot use fixed 
									cutout sizes. Most previous work has resorted to selecting a large cutout size for which "most galaxies"
									would remain in the frame. However, this means that for many galaxies in the dataset, especially smaller 
									ones, typical cutouts contain other galaxies in the frame, often leading to less accurate results. <b><em>
									Thus, this becomes a problem when applying CNNs to galaxies over a wide magnitude and redshift range.</em></b>
								</p>

								<p>In order to address both these challenges, we developed GaMPEN.

									
									<ul>
										<li><b>GaMPEN automatically crops input images to an optimal size before determining
										their morphology.</b></li>
										<li><b>GaMPEN estimates Bayesian posterior distributions for a galaxy's bulge-to-total
										light ratio ($L_B/L_T$), radius($R_e$), and flux. (It can be easily adapted to
										predict other parameters).</li></b>
										<li>GaMPEN takes into account both aleatoric &amp; epistemic uncertainties</li>
										<li>GaMPEN's produced uncertainties/posteriors are extremely well-calibrated and 
										accurate. ($\lesssim 5\%$ derivation)</li>
										<li>GaMPEN incorporates the full covariance matrix in its loss function allowing it to 
										achieve well-calibrated uncertainties for all three variables simultaneously.</li>
									</ul>

									<b><em>GaMPEN is the first machine learning framework for determining joint posterior 
										distributions of multiple morphological parameters and is also the first 
										application of an STN to optical imaging in astronomy.</em></b>
								</p>

								<hr />

								<h3 id="architecture">GaMPEN's Architecture</h3>

								<p>
									<span class="image fit" style="max-width: 80%;
									display: block;
 									margin-left: auto;
  									margin-right: auto;">
									<img src="images/research/gampen/gampen_schematic.png" alt="Image showing
									a schematic diagram of GaMPEN's architecture"/>
										<figattr>GaMPEN consists of an upstream Spatial Transformer Network (STN)
										followed by a downstream Convolutional Neural Network (CNN)
										</figattr>
									</span>

									GaMPEN's architecture consists of two separate entities:- a) an upstream 
									Spatial Transformer Network (STN) which enables GaMPEN to automatically crop
									galaxies to an optimal size; b) a downstream Convolutional Neural Network (CNN)
									which enables GaMPEN to predict posterior distributions for various morphological
									parameters.
								</p>

								<p>GaMPEN's design is based on our previously successful classification CNN, 
								   <a href="gamornet.html">GaMorNet</a>, as well as as different variants of the 
								   Oxford Visual Geometry Group networks. We tried a variety of different architectures
								   before finally converging on this design.
								</p>

								<hr />

								<h3 id="cropping">How does GaMPEN automatically crop galaxies?</h3>
							
								<span class="image fit" style="max-width: 70%;
									display: block;
 									margin-left: auto;
  									margin-right: auto;">
									<img src="images/research/gampen/stn_examples.png" alt="Image showing
									the STN crops applied to six randomly chosen simulated galaxies"/>
									<figattr>Examples of the transformation applied by the STN to six randomly 
										selected simulated galaxy images.</figattr>
								</span>

								<p>In GaMPEN, the STN is upstream of the CNN, where it applies a two-dimensional affine 
									transformation to the input image. <em>Each input image is transformed differently by the STN, 
									which learns the appropriate cropping during the training of the downstream CNN without 
									additional supervision.</em></p>

								<p>To perform the transformation the STN predicts the six-parameter matrix of the affine transformation
									$A_{\theta}$ to be applied to the input image.

									$$ 
									\left(\begin{array}{c}
									x_{i}^{s} \\
									y_{i}^{s}
									\end{array}\right) = A_{\theta}\left(\begin{array}{c}
									x_{i}^{t} \\
									y_{i}^{t} \\
									1
									\end{array}\right) 
									= \left[\begin{array}{lll}
									\theta_{11} & \theta_{12} & \theta_{13} \\
									\theta_{21} & \theta_{22} & \theta_{23}
									\end{array}\right]\left(\begin{array}{c}
									x_{i}^{t} \\
									y_{i}^{t} \\
									1
									\end{array}\right)
									$$

									where $ \left(x_i^s,y_i^s\right)$ and $ \left( x_i^t, y_i^t \right) $ are the source and target 
									co-ordinates respectively. As the network trains, the predicted transformation alters slowly based
									on the loss function.
								</p>

								<p>

									<span class="image left" style="max-width: 35%;"><img 
										src="images/research/gampen/stn_examples_real_data.png" 
										alt="Image showing the performance of the STN on three galaxies 
										from the Hyper Suprime-Cam Wide Survey."/>
										<figattr> Examples of the transformation applied by the STN to three randomly 
											selected $z < 0.25 $ galaxies in the Hyper Suprime-Cam Wide Survey
										</figattr>
									</span>

									<em>Placing the STN upstream in the GaMPEN framework allows the network to learn how to 
									actively transform the input image in such a way that minimizes the overall loss 
									function (i.e., the predicted transformation is guided by and helps the downstream 
									morphological parameter estimation).</em> Because the transformation we use is differentiable with respect to the parameters, 
									gradients can be backpropagated to the predicted parameters $A_{\theta}$. 
									<em>This crucial property allows the STN to be trained using standard backpropagation 
									along with the downstream CNN, without any additional supervision.</em>
								</p>

								<p>The primary benefit of using an STN is that:- <b><em>without any additional training needed, 
									the STN learns to systematically crop out secondary galaxies in the cutouts and focus on 
									the galaxy of interest at the center of the cutout.</b></em></p>

								<hr />

								<h3 id="rot_trans">Prediction Stability Against Rotational Transformations</h3>

								<span class="image fit" style="max-width: 75%;
									display: block;
 									margin-left: auto;
  									margin-right: auto;">
									<img src="images/research/real_data_gampen_video_high_res.gif" 
									alt="Video showing how stable predictions by our neural network
									GaMPEN are against rotations."/>
									<figattr>This video is optimized for fast loading. For a higher resolution version,
										watch it on <a href="https://youtu.be/Oj3QXqZ19-4" target="_blank">YouTube</a>
									</figattr>
								</span>

								<p>Although CNNs learn to recognize features that are 
								   invariant under translation -- the learned features are typically not rotationally
								   invariant. However, this is a problem if CNNs are to be used in astronomy -- especially,
								   for determining the morphology of galaxies. A CNN should be able to identify the same 
								   galaxy at two different orientations and return the same values. <em>But is this true?
								   To what level are the predictions stable? </em>
								</p>

								<p>The above video shows the stability of predictions by GaMPEN when an input galaxy image
								   is rotated through various angles. GaMPEN's predictions of all three 
								   output parameters -- bulge-to-total light ratio ($L_B/L_T$), effective radius ($R_e$),
								   and flux -- are stable against rotations.The modes of the predicted values deviate by
								   $\lesssim 5\%$. <b><em>This importantly shows to what level the predictions are stable 
								   against rotations.
								   </em></b>
								</p> 

								<hr/>

								<h3 id="uncertainties">Posterior Estimation/Uncertainty Prediction</h3>

								<p>
								<span class="image fit" style="max-width: 75%;
									display: block;
 									margin-left: auto;
  									margin-right: auto;">
									<img src="images/research/gampen/workflow_gampen.png" 
									alt="Diagram showing how uncertainties are predicted by GaMPEN"/>
									<figattr>Workflow diagram demonstrating how GaMPEN estimates posterior distributions</figattr>
								</span>

								To create a Bayesian framework while predicting morphological parameters, we have to treat the model 
								itself as a random variable---or more precisely, the weights of our network $\boldsymbol{\omega}$, 
								must be probabilistic distributions instead of single deterministic values. For a network with 
								weights, $\boldsymbol{\omega}$, and a training dataset, $\mathcal{D}$, of size $N$ with input 
								images $\left\{\boldsymbol{X}_{1}, \ldots, \boldsymbol{X}_{N}\right\}$ and output parameters 
								$\left\{\boldsymbol{Y}_{1}, \ldots, \boldsymbol{Y}_{N}\right\}$, the posterior of the network weights, 
								$p(\boldsymbol{\omega} \mid \mathcal{D}) $ represents the plausible network parameters. To predict the 
								probability distribution of the output variable $\boldsymbol{\hat{Y}}$ given a new test 
								image $\boldsymbol{\hat{X}}$, we need to marginalize over all possible weights $\boldsymbol{\omega}$:

								$$
								p(\boldsymbol{\hat{Y}} \mid \boldsymbol{\hat{X}}, \mathcal{D})=\int p(\boldsymbol{\hat{Y}} \mid \boldsymbol{\hat{X}}, \boldsymbol{\omega}) p(\boldsymbol{\omega} \mid \mathcal{D}) d \boldsymbol{\omega} .
								$$

								Using variational inference and dropout, we can approximate the integral in as 

								$$
								\int p(\boldsymbol{\hat{Y}} \mid \boldsymbol{\hat{X}}, \boldsymbol{\omega}) p(\boldsymbol{\omega} \mid \mathcal{D}) d \boldsymbol{\omega} \approx \frac{1}{T} \sum_{t=1}^{T} p(\boldsymbol{\hat{Y}} \mid \boldsymbol{\hat{X}}, \boldsymbol{\omega}_t) ,
								$$

								wherein we perform $T$ forward passes with dropout enabled and $\boldsymbol{\omega}_t$ is the 
								set of weights during the $t^{th}$ forward pass. This procedure is what is referred to as 
								Monte Carlo Dropout. <em><b>However, only performing Monte Carlo dropout is not enough!</b></em>
								</p>

								<p>Our training data consists of noisy input images by design, but we know the corresponding morphological 
									parameters with perfect accuracy. However, due to the different amounts of noise in each image, the 
									predictions of GaMPEN at test time should have different levels of uncertainties. Thus, 
									in this situation, we train GaPEN to predict aleatoric uncertainties.</p>

								<p>Although we would like to use GaMPEN to predict aleatoric uncertainties, the covariance matrix,
									 $\boldsymbol{\Sigma}$, is not known {\it a priori}. Instead, we train GaMPEN to learn these 
									 values by minimizing the negative log-likelihood of the output parameters for the training set, 
									 which can be written as
									
									 $$
									 \begin{split}
									- \log \mathcal{L}_{VI} \propto  \sum_{n} & \frac{1}{2}\left[\boldsymbol{Y}_{n}-\boldsymbol{\hat{\mu}}_{n}\right]^{\top} \boldsymbol{\hat{\Sigma_n}}^{-1}\left[\boldsymbol{Y}_{n}-\boldsymbol{\hat{\mu}}_{n}\right] \\ 
									& + \frac{1}{2} \log [\operatorname{det}(\boldsymbol{\hat{\Sigma_n}})] + \lambda \sum_{i}\left\|\boldsymbol{\omega_{i}}\right\|^{2} .
									\end{split}
									$$

									where $\boldsymbol{\hat{\mu}}_n$ and $\boldsymbol{\hat{\Sigma}}_n$ are the mean and covariance matrix of the multivariate 
									Gaussian distribution predicted by GaMPEN for an image, $\boldsymbol{X}_n$. $\lambda$ is the strength of the regularization
									term, and $\boldsymbol{\omega}_i$ are sampled from $q(\boldsymbol{\omega})$. <em>Note that the above function contains the 
									inverse and determinant of the covariance matrix -- calculating can be numerically unstable. Refer to the GaMPEN paper on
									how to navigate this. 
									</em>	
								</p>

								<p>Thus to predict uncertainties:-

								<ul>
									<li>For every image, GaMPEN predicts the parameters of a multivariate Gaussian distribution
										($\boldsymbol{\mu}$,$\boldsymbol{\Sigma}$). We then draw a sample from this distribution.</li>
									<li>Now the network is slightly altered using Monte Carlo Dropout, and the above step is re-performed
										with a slightly different estimate of ($\boldsymbol{\mu}$,$\boldsymbol{\Sigma}$).
									</li>
									<li>The last step is now repeated 1000 times for each galaxy</li>
								</ul>
								</p>

								<p>The combination of the above two steps allows us to estimate robust uncertainties. By testing
									GaMPEN on simulated Hyper Suprime-Cam galaxies, <em><b>we have verified that GaMPEN's predicted
									posteriors are well-calibrated and accurate. ($\lesssim 5\%$ derivation).
									</b></em>
								</p>

								<hr />

								<h3 id="data_release">Data & Code Release</h3>


								<p>
									GaMPEN's source code and documentation can be accessed
									on <a href="https://github.com/aritraghsh09/GaMPEN" target="_blank">GitHub</a>.
								</p>

								<p>
									The HSC morphological parameter catalogs are accessible
									at this <a href="https://gampen.readthedocs.io/en/latest/Public_data.html"
									target="_blank"> link </a>
								
								</p>

								
								
							</section>

					</div>


				<!-- Copyright -->
				<div id="copyright">
					<ul><li>&copy; Aritra Ghosh</li><li>Design: Based on Massively from <a href="https://html5up.net"
						 target="_blank">HTML5 UP</a></li><li>Background Image: <a href="https://apod.nasa.gov/apod/ap180506.html" target="_blank">Dave Lane</a></li><li><a href="https://github.com/aritraghsh09/academic-website" 
						 target="_blank">Website Source Code</a></li></ul>
				</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>